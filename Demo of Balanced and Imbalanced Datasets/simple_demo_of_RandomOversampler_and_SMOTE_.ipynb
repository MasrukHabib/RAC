{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftn9Eg9nEkgH",
        "outputId": "c7394bc8-6813-4770-cd3c-b7adebd1a511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.1.post1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code demonstrates the use of oversampling techniques, specifically Random Oversampling and Synthetic Minority Over-sampling Technique (SMOTE), to address class imbalance in a toy dataset. Initially, a synthetic dataset is generated with a significant class imbalance, where one class comprises 10% and the other 90% of the samples. The dataset is then split into training and testing sets. Two oversampling techniques, RandomOverSampler and SMOTE, are instantiated. RandomOverSampler duplicates instances from the minority class randomly to balance class distribution, while SMOTE generates synthetic samples for the minority class by interpolating between existing samples. The training sets are then oversampled using both techniques separately. The code prints the class distribution before and after oversampling, highlighting the effectiveness of each technique in balancing the class distribution. This process ensures that the machine learning model trained on the balanced dataset can learn equally from both classes, leading to better performance and generalization on unseen data."
      ],
      "metadata": {
        "id": "L4XYBOBAqNmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "# Generating a toy dataset with class imbalance\n",
        "X, y = make_classification(n_classes=2, class_sep=2,\n",
        "                           weights=[0.1, 0.9], n_informative=3, n_redundant=1,\n",
        "                           flip_y=0, n_features=20, n_clusters_per_class=1,\n",
        "                           n_samples=1000, random_state=10)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiate oversampling techniques\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Random Oversampling\n",
        "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "# SMOTE Oversampling\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Checking class distribution after oversampling\n",
        "print(\"Class distribution before Random Oversampling:\", y_train.sum() / len(y_train))\n",
        "print(\"Class distribution after Random Oversampling:\", y_train_ros.sum() / len(y_train_ros))\n",
        "\n",
        "print(\"Class distribution before SMOTE:\", y_train.sum() / len(y_train))\n",
        "print(\"Class distribution after SMOTE:\", y_train_smote.sum() / len(y_train_smote))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B6Cm5zDEmfp",
        "outputId": "95fef00b-3f5c-4526-8331-e4b2942ff018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before Random Oversampling: 0.90375\n",
            "Class distribution after Random Oversampling: 0.5\n",
            "Class distribution before SMOTE: 0.90375\n",
            "Class distribution after SMOTE: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code aims to address class imbalance in a classification problem using a Support Vector Machine (SVC) classifier within a pipeline that incorporates both oversampling and undersampling techniques. First, the dataset is split into training and testing sets. Then, the RandomOverSampler and RandomUnderSampler are defined to handle the imbalance by oversampling the minority class and undersampling the majority class, respectively. Next, an SVC classifier is instantiated. These components are combined into a pipeline, ensuring that resampling is applied before classification. The pipeline is fitted to the training data. Finally, predictions are made on the testing data, and the performance is evaluated using the classification report, which includes metrics such as precision, recall, and F1-score for each class. This approach helps mitigate the impact of class imbalance and improves the generalization performance of the classifier on unseen data."
      ],
      "metadata": {
        "id": "9OPZ_gSaqZE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Assuming X_train, y_train are your training features and labels respectively\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the resampling strategy\n",
        "over_sampler = RandomOverSampler(sampling_strategy='minority')\n",
        "under_sampler = RandomUnderSampler(sampling_strategy='majority')\n",
        "\n",
        "# Define the classifier\n",
        "clf = SVC()\n",
        "\n",
        "# Create a pipeline with resampling and classifier\n",
        "pipeline = Pipeline([\n",
        "    ('over_sampling', over_sampler),\n",
        "    ('under_sampling', under_sampler),\n",
        "    ('classifier', clf)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "TiWBNYqzppRO",
        "outputId": "8cbcf5f4-53d1-407f-8d6e-15afd0fc76bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        23\n",
            "           1       0.99      1.00      1.00       177\n",
            "\n",
            "    accuracy                           0.99       200\n",
            "   macro avg       1.00      0.98      0.99       200\n",
            "weighted avg       1.00      0.99      0.99       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}